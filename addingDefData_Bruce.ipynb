{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_games = pd.read_csv('nfl-football-player-stats/games_1995.csv')\n",
    "all_games.drop([440917], inplace=True)\n",
    "all_games = all_games.set_index('player_id')\n",
    "all_players = pd.read_csv('nfl-football-player-stats/players_1995.csv',index_col='player_id')\n",
    "gamesDef = pd.read_csv('defData12-17.csv',index_col='Tm')\n",
    "gamesDef = gamesDef.drop(columns=[\"Rk\",\"Time\",\"LTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weird situation: player id 1890 (LeGarrette Blount) was on the Steelers in the 11th game of 2014, was \n",
    "# released from the Steelers and played for the Patriots in their 11th game of 2014. Since he didn't touch the ball\n",
    "# with the Steelers, deleted that row b/c it causes errors later on\n",
    "# all_games[(all_games['year'] == 2014) & (all_games['player_id'] == 1890)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary that has fantasy value for each nfl stat\n",
    "half_ppr = {\n",
    "    'rushing_yards': 0.1,\n",
    "    'rushing_touchdowns': 6,\n",
    "    'receiving_receptions': 0.5,\n",
    "    'receiving_yards': 0.1,\n",
    "    'receiving_touchdowns': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset RB position by choosing only RBs with at least 5 rushing attempts\n",
    "# or receiving targets in a given nfl week.\n",
    "subset_position = {\n",
    "    'RB': [['rushing_attempts', 'receiving_targets'], 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_players_thatweek(all_games, all_players, position, year, gamenumber, subset_position):\n",
    "    # return pandas df with player_id as index and column 'name' as player name\n",
    "    ids = all_players[all_players.position == position].index\n",
    "    games = all_games.loc[ids]\n",
    "    stats = subset_position[position][0]\n",
    "    sum_threshold = subset_position[position][1]\n",
    "    # only take RBs with 5 rush attempts or receiving targets (>= sum_threshold)\n",
    "    worth_predicting = games[(games.year == year) & \n",
    "                             (games.game_number == gamenumber) &\n",
    "                             (np.sum(games[stats], axis=1) >= sum_threshold)]\n",
    "    ids = worth_predicting.index\n",
    "    for_df = all_players.loc[ids, 'name']\n",
    "    return pd.DataFrame(data=for_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>player_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10839</th>\n",
       "      <td>Steven Jackson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10586</th>\n",
       "      <td>Carlos Hyde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>Joique Bell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23980</th>\n",
       "      <td>Andre Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17587</th>\n",
       "      <td>Bernard Pierce</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name\n",
       "player_id                \n",
       "10839      Steven Jackson\n",
       "10586         Carlos Hyde\n",
       "1457          Joique Bell\n",
       "23980      Andre Williams\n",
       "17587      Bernard Pierce"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example usage\n",
    "a = get_players_thatweek(all_games, all_players,'RB',2014,11,subset_position)\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_def_data(gamesDef, opps, gameNumber, year):\n",
    "    prevSeasonDef = gamesDef[gamesDef['Year']==(year-1)]\n",
    "    currentSeasonDef = gamesDef[(gamesDef['Year']==year) & (gamesDef['Game']<=(gameNumber-1))]\n",
    "    df = pd.concat((prevSeasonDef, currentSeasonDef))\n",
    "    df.sort_values(by=['Year', 'Game'], axis=0, ascending=False, inplace=True)\n",
    "    df = df.loc[opps]\n",
    "    grouped = df.groupby('Tm', sort=False)\n",
    "    last5_DYP = grouped.nth(list(range(0,5))).groupby('Tm', sort=False).mean()['DY/P']\n",
    "    last5_TO = grouped.nth(list(range(0,5))).groupby('Tm', sort=False).mean()['TO']\n",
    "    DYP = []\n",
    "    TO = []\n",
    "    for i in opps:\n",
    "        DYP.append(last5_DYP[i])\n",
    "        TO.append(last5_TO[i])\n",
    "    return DYP, TO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_response(players, all_games, year, gameNumber, points_dict, def_data):\n",
    "    games = all_games.loc[players.index]\n",
    "    \n",
    "    # compute fpts for each row\n",
    "    games['fpts'] = games['game_number']*0\n",
    "    for stat, value in zip(points_dict.keys(), points_dict.values()):\n",
    "        games['fpts'] = games['fpts'] + games[stat]*value\n",
    "\n",
    "    prev_years = games[(games.year < year) &\n",
    "                       (games.game_number <= 16)]\n",
    "    current_year = games[(games.year == year) &\n",
    "                         (games.game_number < gameNumber)]\n",
    "    next_game = games[(games.year == year) &\n",
    "                     (games.game_number == gameNumber)]\n",
    "    opps = next_game['opponent']\n",
    "    #get oppponents' defense stats\n",
    "    last5_DYP, last5_TO = get_def_data(def_data, opps, gameNumber, year)\n",
    "    \n",
    "    df = pd.concat((prev_years, current_year))\n",
    "    df.sort_values(by=['player_id', 'year', 'game_number'], axis=0,\n",
    "                   ascending=False, inplace=True)\n",
    "    # group dataframe by index\n",
    "    df = df.groupby(df.index)\n",
    "    \n",
    "    num_prev = df.fpts.agg('count').rename('num_prev')\n",
    "    last = df.nth([0]).groupby('player_id').agg('mean').fpts.rename('last')\n",
    "    next_3 = df.nth(list(range(1,4))).groupby('player_id').agg('mean').fpts.rename('next_3')\n",
    "    next_15 = df.nth(list(range(4,19))).groupby('player_id').agg('mean').fpts.rename('next_15')\n",
    "    to_debut = df.nth(list(range(19,300))).groupby('player_id').agg('mean').fpts.rename('to_debut')\n",
    "    \n",
    "    # get response variable, the next game fantasy points \n",
    "    resp = next_game['fpts']\n",
    "\n",
    "    for_return = players.join([num_prev,last, next_3, next_15, to_debut], how='left')\n",
    "    for_return.insert(6, \"last5 DY/P\", last5_DYP)\n",
    "    for_return.insert(7, \"last5 TO\", last5_TO)\n",
    "    for_return.insert(8, \"resp\", resp.values)\n",
    "    return for_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chloe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\Chloe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>num_prev</th>\n",
       "      <th>last</th>\n",
       "      <th>next_3</th>\n",
       "      <th>next_15</th>\n",
       "      <th>to_debut</th>\n",
       "      <th>last5 DY/P</th>\n",
       "      <th>last5 TO</th>\n",
       "      <th>resp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>player_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10839</th>\n",
       "      <td>Steven Jackson</td>\n",
       "      <td>153</td>\n",
       "      <td>5.7</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>10.373333</td>\n",
       "      <td>14.615672</td>\n",
       "      <td>4.67384</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10586</th>\n",
       "      <td>Carlos Hyde</td>\n",
       "      <td>10</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.55198</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>Joique Bell</td>\n",
       "      <td>49</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.966667</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>6.853333</td>\n",
       "      <td>5.68434</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23980</th>\n",
       "      <td>Andre Williams</td>\n",
       "      <td>10</td>\n",
       "      <td>1.1</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.566667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.39738</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17587</th>\n",
       "      <td>Bernard Pierce</td>\n",
       "      <td>39</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>4.113333</td>\n",
       "      <td>4.860000</td>\n",
       "      <td>5.78462</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8152</th>\n",
       "      <td>Frank Gore</td>\n",
       "      <td>142</td>\n",
       "      <td>12.4</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>10.186667</td>\n",
       "      <td>14.371545</td>\n",
       "      <td>5.55198</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13751</th>\n",
       "      <td>Marshawn Lynch</td>\n",
       "      <td>114</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>15.686667</td>\n",
       "      <td>13.013684</td>\n",
       "      <td>4.84612</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19486</th>\n",
       "      <td>Bishop Sankey</td>\n",
       "      <td>10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.36146</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>Bryce Brown</td>\n",
       "      <td>35</td>\n",
       "      <td>10.6</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>3.246667</td>\n",
       "      <td>5.781250</td>\n",
       "      <td>5.60266</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16086</th>\n",
       "      <td>DeMarco Murray</td>\n",
       "      <td>47</td>\n",
       "      <td>16.1</td>\n",
       "      <td>18.266667</td>\n",
       "      <td>19.793333</td>\n",
       "      <td>12.253571</td>\n",
       "      <td>6.49304</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18654</th>\n",
       "      <td>Theo Riddick</td>\n",
       "      <td>22</td>\n",
       "      <td>4.1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>5.68434</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12749</th>\n",
       "      <td>Eddie Lacy</td>\n",
       "      <td>25</td>\n",
       "      <td>24.9</td>\n",
       "      <td>18.766667</td>\n",
       "      <td>14.120000</td>\n",
       "      <td>12.733333</td>\n",
       "      <td>5.06948</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21034</th>\n",
       "      <td>Darren Sproles</td>\n",
       "      <td>131</td>\n",
       "      <td>5.4</td>\n",
       "      <td>8.933333</td>\n",
       "      <td>8.853333</td>\n",
       "      <td>8.048214</td>\n",
       "      <td>5.31874</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22910</th>\n",
       "      <td>Shane Vereen</td>\n",
       "      <td>36</td>\n",
       "      <td>9.7</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>10.853333</td>\n",
       "      <td>4.464706</td>\n",
       "      <td>4.92292</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21291</th>\n",
       "      <td>Jonathan Stewart</td>\n",
       "      <td>84</td>\n",
       "      <td>13.9</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>6.473333</td>\n",
       "      <td>10.113846</td>\n",
       "      <td>5.96988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16794</th>\n",
       "      <td>Branden Oliver</td>\n",
       "      <td>8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>7.233333</td>\n",
       "      <td>15.325000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.53772</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18152</th>\n",
       "      <td>Bobby Rainey</td>\n",
       "      <td>25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.933333</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>1.216667</td>\n",
       "      <td>6.03984</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23658</th>\n",
       "      <td>Terrance West</td>\n",
       "      <td>9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>9.833333</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.96988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21897</th>\n",
       "      <td>Stepfan Taylor</td>\n",
       "      <td>24</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>2.173333</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>5.17342</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10635</th>\n",
       "      <td>Mark Ingram</td>\n",
       "      <td>44</td>\n",
       "      <td>13.2</td>\n",
       "      <td>20.966667</td>\n",
       "      <td>6.613333</td>\n",
       "      <td>7.188000</td>\n",
       "      <td>4.89656</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>Jamaal Charles</td>\n",
       "      <td>89</td>\n",
       "      <td>30.8</td>\n",
       "      <td>20.066667</td>\n",
       "      <td>20.153333</td>\n",
       "      <td>13.007143</td>\n",
       "      <td>5.19424</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919</th>\n",
       "      <td>Benny Cunningham</td>\n",
       "      <td>24</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>5.726667</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>5.85640</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14725</th>\n",
       "      <td>Darren McFadden</td>\n",
       "      <td>77</td>\n",
       "      <td>2.1</td>\n",
       "      <td>8.266667</td>\n",
       "      <td>8.686667</td>\n",
       "      <td>12.231034</td>\n",
       "      <td>4.93712</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8436</th>\n",
       "      <td>Shonn Greene</td>\n",
       "      <td>80</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.453333</td>\n",
       "      <td>8.704918</td>\n",
       "      <td>5.36146</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>C.J. Anderson</td>\n",
       "      <td>14</td>\n",
       "      <td>15.5</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.60068</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10768</th>\n",
       "      <td>Fred Jackson</td>\n",
       "      <td>100</td>\n",
       "      <td>6.9</td>\n",
       "      <td>10.266667</td>\n",
       "      <td>12.013333</td>\n",
       "      <td>11.425926</td>\n",
       "      <td>5.60266</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14151</th>\n",
       "      <td>Doug Martin</td>\n",
       "      <td>27</td>\n",
       "      <td>3.6</td>\n",
       "      <td>8.933333</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>20.237500</td>\n",
       "      <td>6.03984</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7783</th>\n",
       "      <td>Toby Gerhart</td>\n",
       "      <td>69</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.273333</td>\n",
       "      <td>4.502000</td>\n",
       "      <td>5.88216</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11208</th>\n",
       "      <td>Chris Johnson</td>\n",
       "      <td>105</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>12.760000</td>\n",
       "      <td>15.469767</td>\n",
       "      <td>4.88038</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8554</th>\n",
       "      <td>Jonathan Grimes</td>\n",
       "      <td>21</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>5.44446</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22194</th>\n",
       "      <td>Juwan Thompson</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.633333</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.60068</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14897</th>\n",
       "      <td>Jerick McKinnon</td>\n",
       "      <td>10</td>\n",
       "      <td>7.8</td>\n",
       "      <td>9.366667</td>\n",
       "      <td>6.183333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.79494</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14267</th>\n",
       "      <td>Ryan Mathews</td>\n",
       "      <td>59</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>12.786667</td>\n",
       "      <td>12.322500</td>\n",
       "      <td>5.53772</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>Matt Forte</td>\n",
       "      <td>101</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.433333</td>\n",
       "      <td>19.186667</td>\n",
       "      <td>15.142683</td>\n",
       "      <td>5.55154</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>25.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14229</th>\n",
       "      <td>Tre Mason</td>\n",
       "      <td>6</td>\n",
       "      <td>11.9</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.85640</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7342</th>\n",
       "      <td>Devonta Freeman</td>\n",
       "      <td>10</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.266667</td>\n",
       "      <td>4.616667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.67384</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9856</th>\n",
       "      <td>Jeremy Hill</td>\n",
       "      <td>10</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.233333</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.54416</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24043</th>\n",
       "      <td>DeAngelo Williams</td>\n",
       "      <td>115</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.366667</td>\n",
       "      <td>10.306667</td>\n",
       "      <td>11.148958</td>\n",
       "      <td>5.96988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>Alfred Blue</td>\n",
       "      <td>10</td>\n",
       "      <td>15.6</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.433333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.44446</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17732</th>\n",
       "      <td>Chris Polk</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.109091</td>\n",
       "      <td>5.31874</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14591</th>\n",
       "      <td>LeSean McCoy</td>\n",
       "      <td>84</td>\n",
       "      <td>11.1</td>\n",
       "      <td>10.733333</td>\n",
       "      <td>16.433333</td>\n",
       "      <td>15.493846</td>\n",
       "      <td>5.31874</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5697</th>\n",
       "      <td>Anthony Dixon</td>\n",
       "      <td>74</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.233333</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>1.763636</td>\n",
       "      <td>5.60266</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22612</th>\n",
       "      <td>Robert Turbin</td>\n",
       "      <td>42</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.766667</td>\n",
       "      <td>2.886667</td>\n",
       "      <td>3.413043</td>\n",
       "      <td>4.84612</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>Giovani Bernard</td>\n",
       "      <td>23</td>\n",
       "      <td>11.7</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>13.553333</td>\n",
       "      <td>12.725000</td>\n",
       "      <td>5.54416</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11088</th>\n",
       "      <td>Rashad Jennings</td>\n",
       "      <td>59</td>\n",
       "      <td>8.7</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>12.193333</td>\n",
       "      <td>5.410000</td>\n",
       "      <td>5.39738</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22027</th>\n",
       "      <td>De'Anthony Thomas</td>\n",
       "      <td>6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.433333</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.19424</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4860</th>\n",
       "      <td>Isaiah Crowell</td>\n",
       "      <td>10</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>8.550000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.96988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6367</th>\n",
       "      <td>Andre Ellington</td>\n",
       "      <td>25</td>\n",
       "      <td>8.6</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>11.933333</td>\n",
       "      <td>9.433333</td>\n",
       "      <td>5.17342</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18955</th>\n",
       "      <td>Jacquizz Rodgers</td>\n",
       "      <td>57</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>4.586667</td>\n",
       "      <td>6.526316</td>\n",
       "      <td>4.67384</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15817</th>\n",
       "      <td>Alfred Morris</td>\n",
       "      <td>42</td>\n",
       "      <td>14.2</td>\n",
       "      <td>14.766667</td>\n",
       "      <td>10.706667</td>\n",
       "      <td>14.639130</td>\n",
       "      <td>5.13722</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22104</th>\n",
       "      <td>Pierre Thomas</td>\n",
       "      <td>100</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.366667</td>\n",
       "      <td>11.126667</td>\n",
       "      <td>9.728395</td>\n",
       "      <td>4.89656</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20338</th>\n",
       "      <td>Charles Sims</td>\n",
       "      <td>2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.03984</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>Le'Veon Bell</td>\n",
       "      <td>23</td>\n",
       "      <td>10.9</td>\n",
       "      <td>18.866667</td>\n",
       "      <td>16.146667</td>\n",
       "      <td>13.375000</td>\n",
       "      <td>5.31874</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>29.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>LeGarrette Blount</td>\n",
       "      <td>66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>8.840000</td>\n",
       "      <td>6.951064</td>\n",
       "      <td>4.92292</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>Joe Banyard</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.79494</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18630</th>\n",
       "      <td>Trent Richardson</td>\n",
       "      <td>40</td>\n",
       "      <td>2.6</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>8.466667</td>\n",
       "      <td>13.442857</td>\n",
       "      <td>5.55296</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15340</th>\n",
       "      <td>Lamar Miller</td>\n",
       "      <td>39</td>\n",
       "      <td>10.8</td>\n",
       "      <td>8.233333</td>\n",
       "      <td>9.760000</td>\n",
       "      <td>4.705000</td>\n",
       "      <td>4.70154</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9719</th>\n",
       "      <td>Dan Herron</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.55296</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10701</th>\n",
       "      <td>Chris Ivory</td>\n",
       "      <td>49</td>\n",
       "      <td>5.1</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9.206667</td>\n",
       "      <td>6.853333</td>\n",
       "      <td>4.88038</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7155</th>\n",
       "      <td>Justin Forsett</td>\n",
       "      <td>97</td>\n",
       "      <td>23.2</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>6.726667</td>\n",
       "      <td>4.447436</td>\n",
       "      <td>5.78462</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  num_prev  last     next_3    next_15   to_debut  \\\n",
       "player_id                                                                       \n",
       "10839         Steven Jackson       153   5.7  10.500000  10.373333  14.615672   \n",
       "10586            Carlos Hyde        10   3.5   5.200000   4.833333        NaN   \n",
       "1457             Joique Bell        49  13.0   9.966667  11.480000   6.853333   \n",
       "23980         Andre Williams        10   1.1   9.000000   6.566667        NaN   \n",
       "17587         Bernard Pierce        39   3.1   5.833333   4.113333   4.860000   \n",
       "8152              Frank Gore       142  12.4   7.700000  10.186667  14.371545   \n",
       "13751        Marshawn Lynch        114  13.0  25.500000  15.686667  13.013684   \n",
       "19486          Bishop Sankey        10  11.0   7.500000   5.500000        NaN   \n",
       "2556             Bryce Brown        35  10.6   7.200000   3.246667   5.781250   \n",
       "16086         DeMarco Murray        47  16.1  18.266667  19.793333  12.253571   \n",
       "18654           Theo Riddick        22   4.1  14.000000   0.946667   0.366667   \n",
       "12749             Eddie Lacy        25  24.9  18.766667  14.120000  12.733333   \n",
       "21034         Darren Sproles       131   5.4   8.933333   8.853333   8.048214   \n",
       "22910           Shane Vereen        36   9.7  15.700000  10.853333   4.464706   \n",
       "21291       Jonathan Stewart        84  13.9   7.400000   6.473333  10.113846   \n",
       "16794         Branden Oliver         8   4.4   7.233333  15.325000        NaN   \n",
       "18152           Bobby Rainey        25   0.4   9.933333  10.500000   1.216667   \n",
       "23658         Terrance West          9   1.2   9.833333   8.300000        NaN   \n",
       "21897         Stepfan Taylor        24   1.5   6.800000   2.173333   0.180000   \n",
       "10635            Mark Ingram        44  13.2  20.966667   6.613333   7.188000   \n",
       "3772          Jamaal Charles        89  30.8  20.066667  20.153333  13.007143   \n",
       "4919        Benny Cunningham        24   5.8   6.700000   5.726667   1.360000   \n",
       "14725        Darren McFadden        77   2.1   8.266667   8.686667  12.231034   \n",
       "8436            Shonn Greene        80   0.6   1.500000   5.453333   8.704918   \n",
       "421            C.J. Anderson        14  15.5  10.300000   1.080000        NaN   \n",
       "10768           Fred Jackson       100   6.9  10.266667  12.013333  11.425926   \n",
       "14151           Doug Martin         27   3.6   8.933333  12.900000  20.237500   \n",
       "7783           Toby Gerhart         69   0.2   4.500000   5.273333   4.502000   \n",
       "11208         Chris Johnson        105   4.0   7.700000  12.760000  15.469767   \n",
       "8554         Jonathan Grimes        21   5.4   0.233333   2.033333   0.450000   \n",
       "22194         Juwan Thompson        10   1.0   5.633333   2.466667        NaN   \n",
       "14897       Jerick McKinnon         10   7.8   9.366667   6.183333        NaN   \n",
       "14267           Ryan Mathews        59   8.0   2.233333  12.786667  12.322500   \n",
       "7164             Matt Forte        101  20.5  20.433333  19.186667  15.142683   \n",
       "14229              Tre Mason         6  11.9   6.700000  10.100000        NaN   \n",
       "7342        Devonta Freeman         10   2.8   5.266667   4.616667        NaN   \n",
       "9856             Jeremy Hill        10  17.0  14.233333   8.300000        NaN   \n",
       "24043      DeAngelo Williams       115   6.3   5.366667  10.306667  11.148958   \n",
       "1894             Alfred Blue        10  15.6   5.800000   3.433333        NaN   \n",
       "17732             Chris Polk        30   0.0   4.666667   1.580000   1.109091   \n",
       "14591           LeSean McCoy        84  11.1  10.733333  16.433333  15.493846   \n",
       "5697           Anthony Dixon        74   5.8   6.233333   0.973333   1.763636   \n",
       "22612          Robert Turbin        42   1.1   4.766667   2.886667   3.413043   \n",
       "1603         Giovani Bernard        23  11.7  11.500000  13.553333  12.725000   \n",
       "11088        Rashad Jennings        59   8.7  12.500000  12.193333   5.410000   \n",
       "22027      De'Anthony Thomas         6   3.7   2.433333   5.650000        NaN   \n",
       "4860          Isaiah Crowell        10  10.1   3.833333   8.550000        NaN   \n",
       "6367         Andre Ellington        25   8.6  16.700000  11.933333   9.433333   \n",
       "18955      Jacquizz Rodgers         57   2.7   2.800000   4.586667   6.526316   \n",
       "15817         Alfred Morris         42  14.2  14.766667  10.706667  14.639130   \n",
       "22104          Pierre Thomas       100   5.0  14.366667  11.126667   9.728395   \n",
       "20338           Charles Sims         2   5.9   5.000000        NaN        NaN   \n",
       "1465            Le'Veon Bell        23  10.9  18.866667  16.146667  13.375000   \n",
       "1890       LeGarrette Blount        66   0.0   2.900000   8.840000   6.951064   \n",
       "1022             Joe Banyard        12   0.0   0.000000   0.462500        NaN   \n",
       "18630      Trent Richardson         40   2.6   9.700000   8.466667  13.442857   \n",
       "15340           Lamar Miller        39  10.8   8.233333   9.760000   4.705000   \n",
       "9719              Dan Herron        19   0.0   2.266667   0.833333        NaN   \n",
       "10701            Chris Ivory        49   5.1  13.000000   9.206667   6.853333   \n",
       "7155          Justin Forsett        97  23.2  10.833333   6.726667   4.447436   \n",
       "\n",
       "           last5 DY/P  last5 TO  resp  \n",
       "player_id                              \n",
       "10839         4.67384  2.000000  12.1  \n",
       "10586         5.55198  2.200000   7.6  \n",
       "1457          5.68434  1.500000   5.1  \n",
       "23980         5.39738  1.600000  11.2  \n",
       "17587         5.78462  1.800000   3.9  \n",
       "8152          5.55198  2.200000   3.6  \n",
       "13751         4.84612  1.200000   9.7  \n",
       "19486         5.36146  3.250000   6.1  \n",
       "2556          5.60266  4.000000   2.0  \n",
       "16086         6.49304  2.200000  15.3  \n",
       "18654         5.68434  1.500000   6.7  \n",
       "12749         5.06948  2.000000  26.8  \n",
       "21034         5.31874  1.750000  11.4  \n",
       "22910         4.92292  1.250000  10.0  \n",
       "21291         5.96988  1.000000   5.4  \n",
       "16794         5.53772  2.000000   6.0  \n",
       "18152         6.03984  2.500000   4.1  \n",
       "23658         5.96988  1.000000   7.6  \n",
       "21897         5.17342  2.500000   1.4  \n",
       "10635         4.89656  2.000000   5.2  \n",
       "3772          5.19424  2.500000  20.2  \n",
       "4919          5.85640  2.333333   3.9  \n",
       "14725         4.93712  1.333333   4.4  \n",
       "8436          5.36146  3.250000   7.5  \n",
       "421           4.60068  1.666667  27.5  \n",
       "10768         5.60266  4.000000  12.0  \n",
       "14151         6.03984  2.500000   3.6  \n",
       "7783          5.88216  1.750000   6.5  \n",
       "11208         4.88038  3.333333   7.7  \n",
       "8554          5.44446  2.666667   6.3  \n",
       "22194         4.60068  1.666667   3.3  \n",
       "14897         5.79494  2.000000   7.8  \n",
       "14267         5.53772  2.000000  18.3  \n",
       "7164          5.55154  1.800000  25.7  \n",
       "14229         5.85640  2.333333   9.3  \n",
       "7342          4.67384  2.000000   0.7  \n",
       "9856          5.54416  1.750000  16.1  \n",
       "24043         5.96988  1.000000   4.3  \n",
       "1894          5.44446  2.666667   8.1  \n",
       "17732         5.31874  1.750000   2.5  \n",
       "14591         5.31874  1.750000  19.6  \n",
       "5697          5.60266  4.000000  12.7  \n",
       "22612         4.84612  1.200000   2.5  \n",
       "1603          5.54416  1.750000   7.7  \n",
       "11088         5.39738  1.600000  16.0  \n",
       "22027         5.19424  2.500000   3.4  \n",
       "4860          5.96988  1.000000  20.8  \n",
       "6367          5.17342  2.500000   8.8  \n",
       "18955         4.67384  2.000000  10.2  \n",
       "15817         5.13722  1.200000  19.5  \n",
       "22104         4.89656  2.000000   8.6  \n",
       "20338         6.03984  2.500000   4.3  \n",
       "1465          5.31874  1.750000  29.2  \n",
       "1890          4.92292  1.250000  19.8  \n",
       "1022          5.79494  2.000000   6.0  \n",
       "18630         5.55296  2.400000  10.2  \n",
       "15340         4.70154  2.000000   7.2  \n",
       "9719          5.55296  2.400000  12.1  \n",
       "10701         4.88038  3.333333   5.3  \n",
       "7155          5.78462  1.800000  32.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example usage\n",
    "players = get_players_thatweek(all_games, all_players,'RB',2014,11, subset_position)\n",
    "get_features_response(players, all_games, 2014, 11, half_ppr, gamesDef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chloe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\Chloe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\Chloe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "POSITION = 'RB'\n",
    "START_YEAR = 2013\n",
    "YEAR = 2016\n",
    "NFL_WEEK = 5\n",
    "# features \n",
    "FEATURES = ['num_prev', 'last', 'next_3', 'next_15', 'to_debut','last5 DY/P','last5 TO']\n",
    "# response\n",
    "RESPONSE = ['resp']\n",
    "\n",
    "# append features and response each week to these lists\n",
    "feature_list = []\n",
    "response_list = []\n",
    "\n",
    "for year in range(START_YEAR, YEAR+1):   \n",
    "    \n",
    "    # if current year dont go past nfl week\n",
    "    if year == YEAR:\n",
    "        week_limit = NFL_WEEK-1\n",
    "    else: # if previous year don't go past regular season (nfl week 16)\n",
    "        week_limit = 16\n",
    "\n",
    "    for week in range(1,week_limit+1):\n",
    "        #print(\"week: \",week,\" year: \",year)\n",
    "        players = get_players_thatweek(all_games, all_players, POSITION, year, week, subset_position)\n",
    "        train = get_features_response(players, all_games, year, week, half_ppr, gamesDef)\n",
    "        feature = train[FEATURES]\n",
    "        response = train[RESPONSE]\n",
    "        feature_list.append(feature)\n",
    "        response_list.append(response)\n",
    "\n",
    "# At the end concatenate feature and response lists \n",
    "#  into train_x and train_y dataframes\n",
    "train_x = pd.concat(feature_list)\n",
    "train_y = pd.concat(response_list)\n",
    "\n",
    "# fill NaN in train_x with zeros\n",
    "train_x = train_x.fillna(0)\n",
    "\n",
    "# Get test_x and test_y\n",
    "players = get_players_thatweek(all_games, all_players, POSITION, YEAR, NFL_WEEK, subset_position)\n",
    "test = get_features_response(players, all_games, YEAR, NFL_WEEK, half_ppr, gamesDef)\n",
    "test_x = test[FEATURES]\n",
    "test_y = test[RESPONSE]\n",
    "\n",
    "# fill NaN in test_x with zeros\n",
    "test_x = test_x.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [1.34042061]\n",
      "['num_prev', 'last', 'next_3', 'next_15', 'to_debut', 'last5 DY/P', 'last5 TO']\n",
      "[[-0.01080409  0.1740959   0.21513372  0.1582381   0.06468097  0.73462786\n",
      "   0.00882845]]\n",
      "R^2:  0.18890860570007872\n"
     ]
    }
   ],
   "source": [
    "# Train a linear regression model to predict rest of season ppg for RBs\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr = lr.fit(train_x, train_y)\n",
    "print('Intercept:', lr.intercept_)\n",
    "print(FEATURES)\n",
    "print(lr.coef_)\n",
    "print('R^2: ', lr.score(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>resp</td>       <th>  R-squared:         </th> <td>   0.160</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.158</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   84.17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 27 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>2.22e-112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:28:22</td>     <th>  Log-Likelihood:    </th> <td> -10237.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3106</td>      <th>  AIC:               </th> <td>2.049e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3098</td>      <th>  BIC:               </th> <td>2.054e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>      <td>    1.3404</td> <td>    1.195</td> <td>    1.122</td> <td> 0.262</td> <td>   -1.003</td> <td>    3.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_prev</th>   <td>   -0.0108</td> <td>    0.004</td> <td>   -2.415</td> <td> 0.016</td> <td>   -0.020</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last</th>       <td>    0.1741</td> <td>    0.018</td> <td>    9.911</td> <td> 0.000</td> <td>    0.140</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>next_3</th>     <td>    0.2151</td> <td>    0.026</td> <td>    8.381</td> <td> 0.000</td> <td>    0.165</td> <td>    0.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>next_15</th>    <td>    0.1582</td> <td>    0.034</td> <td>    4.592</td> <td> 0.000</td> <td>    0.091</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>to_debut</th>   <td>    0.0647</td> <td>    0.035</td> <td>    1.852</td> <td> 0.064</td> <td>   -0.004</td> <td>    0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last5 DY/P</th> <td>    0.7346</td> <td>    0.200</td> <td>    3.672</td> <td> 0.000</td> <td>    0.342</td> <td>    1.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last5 TO</th>   <td>    0.0088</td> <td>    0.201</td> <td>    0.044</td> <td> 0.965</td> <td>   -0.385</td> <td>    0.403</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>569.378</td> <th>  Durbin-Watson:     </th> <td>   2.044</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1075.388</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.122</td>  <th>  Prob(JB):          </th> <td>3.04e-234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.809</td>  <th>  Cond. No.          </th> <td>    652.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   resp   R-squared:                       0.160\n",
       "Model:                            OLS   Adj. R-squared:                  0.158\n",
       "Method:                 Least Squares   F-statistic:                     84.17\n",
       "Date:                Wed, 27 Nov 2019   Prob (F-statistic):          2.22e-112\n",
       "Time:                        00:28:22   Log-Likelihood:                -10237.\n",
       "No. Observations:                3106   AIC:                         2.049e+04\n",
       "Df Residuals:                    3098   BIC:                         2.054e+04\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.3404      1.195      1.122      0.262      -1.003       3.683\n",
       "num_prev      -0.0108      0.004     -2.415      0.016      -0.020      -0.002\n",
       "last           0.1741      0.018      9.911      0.000       0.140       0.209\n",
       "next_3         0.2151      0.026      8.381      0.000       0.165       0.265\n",
       "next_15        0.1582      0.034      4.592      0.000       0.091       0.226\n",
       "to_debut       0.0647      0.035      1.852      0.064      -0.004       0.133\n",
       "last5 DY/P     0.7346      0.200      3.672      0.000       0.342       1.127\n",
       "last5 TO       0.0088      0.201      0.044      0.965      -0.385       0.403\n",
       "==============================================================================\n",
       "Omnibus:                      569.378   Durbin-Watson:                   2.044\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1075.388\n",
       "Skew:                           1.122   Prob(JB):                    3.04e-234\n",
       "Kurtosis:                       4.809   Cond. No.                         652.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using statsmodels\n",
    "import statsmodels.api as sm \n",
    "X_train = sm.add_constant(train_x)\n",
    "# Fit OLS model \n",
    "model = sm.OLS(train_y, X_train).fit() \n",
    "# Print model summary \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  49.502233400558026\n"
     ]
    }
   ],
   "source": [
    "X_test = sm.add_constant(test_x)\n",
    "preds = model.predict(X_test) \n",
    "#MSE\n",
    "sse = 0\n",
    "for i in range(len(preds)):\n",
    "    sse += (preds.values[i] - test_y.values[i][0])**2\n",
    "print(\"MSE: \", sse/len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>resp</td>       <th>  R-squared:         </th> <td>   0.160</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.158</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   98.22</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 27 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>2.15e-113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:28:23</td>     <th>  Log-Likelihood:    </th> <td> -10237.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3106</td>      <th>  AIC:               </th> <td>2.049e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3099</td>      <th>  BIC:               </th> <td>2.053e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>      <td>    1.3594</td> <td>    1.114</td> <td>    1.221</td> <td> 0.222</td> <td>   -0.824</td> <td>    3.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_prev</th>   <td>   -0.0108</td> <td>    0.004</td> <td>   -2.418</td> <td> 0.016</td> <td>   -0.020</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last</th>       <td>    0.1741</td> <td>    0.018</td> <td>    9.913</td> <td> 0.000</td> <td>    0.140</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>next_3</th>     <td>    0.2151</td> <td>    0.026</td> <td>    8.383</td> <td> 0.000</td> <td>    0.165</td> <td>    0.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>next_15</th>    <td>    0.1582</td> <td>    0.034</td> <td>    4.592</td> <td> 0.000</td> <td>    0.091</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>to_debut</th>   <td>    0.0647</td> <td>    0.035</td> <td>    1.854</td> <td> 0.064</td> <td>   -0.004</td> <td>    0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last5 DY/P</th> <td>    0.7344</td> <td>    0.200</td> <td>    3.673</td> <td> 0.000</td> <td>    0.342</td> <td>    1.126</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>569.379</td> <th>  Durbin-Watson:     </th> <td>   2.044</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1075.411</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.122</td>  <th>  Prob(JB):          </th> <td>3.00e-234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.809</td>  <th>  Cond. No.          </th> <td>    608.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   resp   R-squared:                       0.160\n",
       "Model:                            OLS   Adj. R-squared:                  0.158\n",
       "Method:                 Least Squares   F-statistic:                     98.22\n",
       "Date:                Wed, 27 Nov 2019   Prob (F-statistic):          2.15e-113\n",
       "Time:                        00:28:23   Log-Likelihood:                -10237.\n",
       "No. Observations:                3106   AIC:                         2.049e+04\n",
       "Df Residuals:                    3099   BIC:                         2.053e+04\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.3594      1.114      1.221      0.222      -0.824       3.543\n",
       "num_prev      -0.0108      0.004     -2.418      0.016      -0.020      -0.002\n",
       "last           0.1741      0.018      9.913      0.000       0.140       0.209\n",
       "next_3         0.2151      0.026      8.383      0.000       0.165       0.265\n",
       "next_15        0.1582      0.034      4.592      0.000       0.091       0.226\n",
       "to_debut       0.0647      0.035      1.854      0.064      -0.004       0.133\n",
       "last5 DY/P     0.7344      0.200      3.673      0.000       0.342       1.126\n",
       "==============================================================================\n",
       "Omnibus:                      569.379   Durbin-Watson:                   2.044\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1075.411\n",
       "Skew:                           1.122   Prob(JB):                    3.00e-234\n",
       "Kurtosis:                       4.809   Cond. No.                         608.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# worse than before!\n",
    "# trying it without TO\n",
    "X_train2 = sm.add_constant(train_x.drop(columns=['last5 TO']))\n",
    "model2 = sm.OLS(train_y, X_train2).fit() \n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  49.513578585021804\n"
     ]
    }
   ],
   "source": [
    "X_test2 = sm.add_constant(test_x.drop(columns=['last5 TO']))\n",
    "preds2 = model2.predict(X_test2) \n",
    "#MSE\n",
    "sse = 0\n",
    "for i in range(len(preds)):\n",
    "    sse += (preds2.values[i] - test_y.values[i][0])**2\n",
    "print(\"MSE: \", sse/len(preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>resp</td>       <th>  R-squared:         </th> <td>   0.160</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.158</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   98.22</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 27 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>2.15e-113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:28:23</td>     <th>  Log-Likelihood:    </th> <td> -10237.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3106</td>      <th>  AIC:               </th> <td>2.049e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3099</td>      <th>  BIC:               </th> <td>2.053e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    9.9730</td> <td>    0.117</td> <td>   84.979</td> <td> 0.000</td> <td>    9.743</td> <td>   10.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.4097</td> <td>    0.169</td> <td>   -2.418</td> <td> 0.016</td> <td>   -0.742</td> <td>   -0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    1.3228</td> <td>    0.133</td> <td>    9.913</td> <td> 0.000</td> <td>    1.061</td> <td>    1.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    1.2730</td> <td>    0.152</td> <td>    8.383</td> <td> 0.000</td> <td>    0.975</td> <td>    1.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.8257</td> <td>    0.180</td> <td>    4.592</td> <td> 0.000</td> <td>    0.473</td> <td>    1.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.3687</td> <td>    0.199</td> <td>    1.854</td> <td> 0.064</td> <td>   -0.021</td> <td>    0.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.4312</td> <td>    0.117</td> <td>    3.673</td> <td> 0.000</td> <td>    0.201</td> <td>    0.661</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>569.379</td> <th>  Durbin-Watson:     </th> <td>   2.044</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1075.411</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.122</td>  <th>  Prob(JB):          </th> <td>3.00e-234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.809</td>  <th>  Cond. No.          </th> <td>    3.53</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   resp   R-squared:                       0.160\n",
       "Model:                            OLS   Adj. R-squared:                  0.158\n",
       "Method:                 Least Squares   F-statistic:                     98.22\n",
       "Date:                Wed, 27 Nov 2019   Prob (F-statistic):          2.15e-113\n",
       "Time:                        00:28:23   Log-Likelihood:                -10237.\n",
       "No. Observations:                3106   AIC:                         2.049e+04\n",
       "Df Residuals:                    3099   BIC:                         2.053e+04\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          9.9730      0.117     84.979      0.000       9.743      10.203\n",
       "x1            -0.4097      0.169     -2.418      0.016      -0.742      -0.077\n",
       "x2             1.3228      0.133      9.913      0.000       1.061       1.584\n",
       "x3             1.2730      0.152      8.383      0.000       0.975       1.571\n",
       "x4             0.8257      0.180      4.592      0.000       0.473       1.178\n",
       "x5             0.3687      0.199      1.854      0.064      -0.021       0.759\n",
       "x6             0.4312      0.117      3.673      0.000       0.201       0.661\n",
       "==============================================================================\n",
       "Omnibus:                      569.379   Durbin-Watson:                   2.044\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1075.411\n",
       "Skew:                           1.122   Prob(JB):                    3.00e-234\n",
       "Kurtosis:                       4.809   Cond. No.                         3.53\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalizing features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train3 = sm.add_constant(StandardScaler().fit_transform(train_x.drop(columns=['last5 TO'])))\n",
    "model3 = sm.OLS(train_y, X_train3).fit() \n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  49.29470020205491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chloe\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Chloe\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "X_test3 = sm.add_constant(StandardScaler().fit_transform(test_x.drop(columns=['last5 TO'])))\n",
    "preds3 = model3.predict(X_test3) \n",
    "#MSE\n",
    "sse = 0\n",
    "for i in range(len(preds)):\n",
    "    sse += (preds3[i] - test_y.values[i][0])**2\n",
    "print(\"MSE: \", sse/len(preds3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>resp</td>       <th>  R-squared:         </th> <td>   0.156</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.155</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   114.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 27 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>1.52e-111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:29:56</td>     <th>  Log-Likelihood:    </th> <td> -10244.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3106</td>      <th>  AIC:               </th> <td>2.050e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3100</td>      <th>  BIC:               </th> <td>2.054e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>    5.3431</td> <td>    0.253</td> <td>   21.123</td> <td> 0.000</td> <td>    4.847</td> <td>    5.839</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num_prev</th> <td>   -0.0109</td> <td>    0.004</td> <td>   -2.437</td> <td> 0.015</td> <td>   -0.020</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last</th>     <td>    0.1732</td> <td>    0.018</td> <td>    9.844</td> <td> 0.000</td> <td>    0.139</td> <td>    0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>next_3</th>   <td>    0.2137</td> <td>    0.026</td> <td>    8.309</td> <td> 0.000</td> <td>    0.163</td> <td>    0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>next_15</th>  <td>    0.1608</td> <td>    0.035</td> <td>    4.658</td> <td> 0.000</td> <td>    0.093</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>to_debut</th> <td>    0.0648</td> <td>    0.035</td> <td>    1.853</td> <td> 0.064</td> <td>   -0.004</td> <td>    0.133</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>569.293</td> <th>  Durbin-Watson:     </th> <td>   2.044</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1072.689</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.123</td>  <th>  Prob(JB):          </th> <td>1.17e-233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.800</td>  <th>  Cond. No.          </th> <td>    136.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   resp   R-squared:                       0.156\n",
       "Model:                            OLS   Adj. R-squared:                  0.155\n",
       "Method:                 Least Squares   F-statistic:                     114.7\n",
       "Date:                Wed, 27 Nov 2019   Prob (F-statistic):          1.52e-111\n",
       "Time:                        00:29:56   Log-Likelihood:                -10244.\n",
       "No. Observations:                3106   AIC:                         2.050e+04\n",
       "Df Residuals:                    3100   BIC:                         2.054e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          5.3431      0.253     21.123      0.000       4.847       5.839\n",
       "num_prev      -0.0109      0.004     -2.437      0.015      -0.020      -0.002\n",
       "last           0.1732      0.018      9.844      0.000       0.139       0.208\n",
       "next_3         0.2137      0.026      8.309      0.000       0.163       0.264\n",
       "next_15        0.1608      0.035      4.658      0.000       0.093       0.228\n",
       "to_debut       0.0648      0.035      1.853      0.064      -0.004       0.133\n",
       "==============================================================================\n",
       "Omnibus:                      569.293   Durbin-Watson:                   2.044\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1072.689\n",
       "Skew:                           1.123   Prob(JB):                    1.17e-233\n",
       "Kurtosis:                       4.800   Cond. No.                         136.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without defense data?\n",
    "X_train4 = sm.add_constant(train_x.drop(columns=['last5 TO','last5 DY/P']))\n",
    "model4 = sm.OLS(train_y, X_train4).fit() \n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  48.79041319742892\n"
     ]
    }
   ],
   "source": [
    "X_test4 = sm.add_constant(test_x.drop(columns=['last5 TO','last5 DY/P']))\n",
    "preds4 = model4.predict(X_test4) \n",
    "#MSE\n",
    "sse = 0\n",
    "for i in range(len(preds)):\n",
    "    sse += (preds4.values[i] - test_y.values[i][0])**2\n",
    "print(\"MSE: \", sse/len(preds4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [9.97301996]\n",
      "['num_prev', 'last', 'next_3', 'next_15', 'to_debut', 'last5 DY/P', 'last5 TO']\n",
      "[[ 0.         -0.40965582  1.32279173  1.27300699  0.82570868  0.36871887\n",
      "   0.43116449]]\n",
      "R^2:  0.19230902583820453\n",
      "MSE:  [49.2947002]\n"
     ]
    }
   ],
   "source": [
    "# including last5 DY/P and scaled features\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train3, train_y)\n",
    "print('Intercept:', lr.intercept_)\n",
    "print(FEATURES)\n",
    "print(lr.coef_)\n",
    "print('R^2: ', lr.score(X_test3, test_y))\n",
    "preds = lr.predict(X_test3)\n",
    "print(\"MSE: \",sum((preds - test_y.values)**2)/len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [5.34310396]\n",
      "['num_prev', 'last', 'next_3', 'next_15', 'to_debut', 'last5 DY/P', 'last5 TO']\n",
      "[[ 0.         -0.01091709  0.17321945  0.21365332  0.16079936  0.06480533]]\n",
      "R^2:  0.20057174090400287\n",
      "MSE:  [48.7904132]\n"
     ]
    }
   ],
   "source": [
    "# without defense data\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train4, train_y)\n",
    "print('Intercept:', lr.intercept_)\n",
    "print(FEATURES)\n",
    "print(lr.coef_)\n",
    "print('R^2: ', lr.score(X_test4, test_y))\n",
    "preds = lr.predict(X_test4)\n",
    "print(\"MSE: \",sum((preds - test_y.values)**2)/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:  0.15103945151350318\n",
      "MSE:  51.81344977198023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "# including last5 DY/P and scaled features\n",
    "las_model = Lasso()\n",
    "las_model.fit(X_train3, train_y)\n",
    "print('R^2: ', las_model.score(X_test3, test_y))\n",
    "preds = las_model.predict(X_test3)\n",
    "#MSE\n",
    "sse = 0\n",
    "for i in range(len(preds)):\n",
    "    sse += (preds[i] - test_y.values[i][0])**2\n",
    "print(\"MSE: \", sse/len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:  0.19216288202291143\n",
      "MSE:  49.30361959795226\n"
     ]
    }
   ],
   "source": [
    "#without defense data\n",
    "las_model = Lasso()\n",
    "las_model.fit(X_train4, train_y)\n",
    "print('R^2: ', las_model.score(X_test4, test_y))\n",
    "preds = las_model.predict(X_test4)\n",
    "#MSE\n",
    "sse = 0\n",
    "for i in range(len(preds)):\n",
    "    sse += (preds[i] - test_y.values[i][0])**2\n",
    "print(\"MSE: \", sse/len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chloe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:  0.19071478629844218\n",
      "MSE:  49.39199924671046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(n_estimators=400)\n",
    "rf_model.fit(X_train3, train_y)\n",
    "preds = rf_model.predict(X_test3)\n",
    "print('R^2: ', rf_model.score(X_test3, test_y))\n",
    "#MSE\n",
    "sse = 0\n",
    "for i in range(len(preds)):\n",
    "    sse += (preds[i] - test_y.values[i][0])**2\n",
    "print(\"MSE: \", sse/len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chloe\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:  0.15700236412482527\n",
      "MSE:  51.44952346983079\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=400)\n",
    "rf_model.fit(X_train4, train_y)\n",
    "preds = rf_model.predict(X_test4)\n",
    "print('R^2: ', rf_model.score(X_test4, test_y))\n",
    "#MSE\n",
    "sse = 0\n",
    "for i in range(len(preds)):\n",
    "    sse += (preds[i] - test_y.values[i][0])**2\n",
    "print(\"MSE: \", sse/len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
